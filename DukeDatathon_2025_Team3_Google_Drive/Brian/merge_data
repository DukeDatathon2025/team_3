{"cells":[{"cell_type":"code","source":["# prompt: I have data files in Drive in \"DukeDatathon_2025_Team3/Brian/files/'. I want to load these in and create a dictionary where the key is the name of the file and the value is the df after loading in. fyi this folder is shared with me\n","\n","from google.colab import drive\n","import pandas as pd\n","import os\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Specify the path to your data files\n","data_dir = '/content/drive/MyDrive/DukeDatathon_2025_Team3/Brian/files/'\n","\n","# Create an empty dictionary to store the dataframes\n","data_dict = {}\n","\n","# Iterate through all files in the specified directory\n","for filename in os.listdir(data_dir):\n","    # Check if the file is a CSV file\n","    if filename.endswith('.csv'):\n","      try:\n","        # Construct the full file path\n","        filepath = os.path.join(data_dir, filename)\n","\n","        # Load the CSV file into a pandas DataFrame\n","        df = pd.read_csv(filepath)\n","\n","        # Add the DataFrame to the dictionary with the filename (without extension) as the key\n","        data_dict[filename[:-4]] = df\n","        print(f\"Loaded {filename} into data_dict\")\n","      except Exception as e:\n","        print(f\"Error loading {filename}: {e}\")\n","    #Handle other file types here if needed (e.g., Excel)\n","    elif filename.endswith(('.xls', '.xlsx')):\n","      try:\n","        filepath = os.path.join(data_dir, filename)\n","        df = pd.read_excel(filepath)\n","        data_dict[filename[:-4]] = df\n","        print(f\"Loaded {filename} into data_dict\")\n","      except Exception as e:\n","        print(f\"Error loading {filename}: {e}\")\n","    else:\n","      print(f\"Skipping {filename} - unsupported file format\")\n","\n","# Now you can access each DataFrame using its filename (without extension) as the key\n","# For example:\n","# if 'your_file_name' in data_dict:\n","#   df = data_dict['your_file_name']\n","#   print(df.head())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":233},"id":"XcwGtJhsM6JV","executionInfo":{"status":"error","timestamp":1745752380133,"user_tz":240,"elapsed":607,"user":{"displayName":"Bryce Hendren-Santiago","userId":"18389451551274920537"}},"outputId":"0298e29f-cbf6-4133-b236-759aecfde529"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/MyDrive/DukeDatathon_2025_Team3/Brian/files/'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-be58e480cc18>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Iterate through all files in the specified directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Check if the file is a CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/DukeDatathon_2025_Team3/Brian/files/'"]}]},{"cell_type":"code","source":["for df_name, df in data_dict.items():\n","  print(f\"DataFrame Name: {df_name}\")\n","  print(f\"Shape: {df.shape}\")\n","  print(f\"Columns: {df.columns.tolist()}\")\n","  print(\"-\" * 20)"],"metadata":{"id":"cWGkAiSVOeUT","executionInfo":{"status":"ok","timestamp":1745752386365,"user_tz":240,"elapsed":3,"user":{"displayName":"Bryce Hendren-Santiago","userId":"18389451551274920537"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["df_admissions.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":144},"id":"tyxsHOBCtAEu","executionInfo":{"status":"error","timestamp":1745752398096,"user_tz":240,"elapsed":12,"user":{"displayName":"Bryce Hendren-Santiago","userId":"18389451551274920537"}},"outputId":"1e96eff7-023c-4f1d-b732-f59339f73f4d"},"execution_count":6,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'df_admissions' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-cfca6091d7da>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_admissions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'df_admissions' is not defined"]}]},{"cell_type":"code","source":["for df_name, df in data_dict.items():\n","  for col in df.columns:\n","    if 'time' in col.lower():\n","      try:\n","        df[col] = pd.to_datetime(df[col])\n","        print(f\"Converted '{col}' in '{df_name}' to datetime.\")\n","      except (ValueError, TypeError) as e:\n","        print(f\"Error converting '{col}' in '{df_name}' to datetime: {e}\")\n"],"metadata":{"id":"ngWi0g6xQvBz","executionInfo":{"status":"ok","timestamp":1745752400856,"user_tz":240,"elapsed":4,"user":{"displayName":"Bryce Hendren-Santiago","userId":"18389451551274920537"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["df_sofa = data_dict[\"sofa\"]\n","df_admissions = data_dict[\"admissions\"]\n","df_patients = data_dict[\"patients\"]\n","df_charlson = data_dict[\"charlson\"]\n","df_sepsis3 = data_dict[\"sepsis3\"]\n","df_age = data_dict[\"age\"]\n","df_first_day_sofa = data_dict[\"first_day_sofa\"]\n","df_icustays = data_dict[\"icustays\"]"],"metadata":{"id":"Rgsu6GJrOlfO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Merging"],"metadata":{"id":"3HlzVEKutkqZ"}},{"cell_type":"code","source":["# COLS TO KEEP\n","# df_sepsis3\n","# Columns: ['subject_id', 'stay_id', 'antibiotic_time', 'culture_time', 'suspected_infection_time', 'sofa_time', 'sofa_score', 'respiration', 'coagulation', 'liver', 'cardiovascular', 'cns', 'renal', 'sepsis3']\n","# --------------------\n","# df_age\n","# Columns: ['subject_id', 'hadm_id', 'age']\n","# --------------------\n","# df_charlson\n","# Columns: ['subject_id', 'hadm_id', 'charlson_comorbidity_index']\n","# --------------------\n","# df_patients\n","# Columns: ['subject_id', 'gender']\n","# --------------------\n","# df_admissions\n","# Columns: ['subject_id', 'hadm_id', 'deathtime', 'insurance', 'language', 'race', 'hospital_expire_flag']\n","# --------------------\n","# df_first_day_sofa\n","# Columns: ['subject_id', 'hadm_id', 'stay_id', 'sofa']\n","# --------------------\n","# df_icustays\n","# Columns: ['subject_id', 'hadm_id', 'stay_id', 'intime']\n","--------------------"],"metadata":{"id":"cDApbdHwtopq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# prompt: make a function that compares how many unique stayid in two df (before and after)\n","\n","def compare_unique_stayid(df1, df2):\n","  \"\"\"\n","  Compares the number of unique stay IDs in two dataframes.\n","\n","  Args:\n","    df1: The first dataframe.\n","    df2: The second dataframe.\n","\n","  Returns:\n","    A tuple containing:\n","      - The number of unique stay IDs in df1.\n","      - The number of unique stay IDs in df2.\n","      - The difference in the number of unique stay IDs between df1 and df2.\n","  \"\"\"\n","  unique_stayid_df1 = df1['stay_id'].nunique()\n","  unique_stayid_df2 = df2['stay_id'].nunique()\n","  difference = unique_stayid_df1 - unique_stayid_df2\n","  print(f\"Number of unique stay IDs in df1: {unique_stayid_df1}\")\n","  print(f\"Number of unique stay IDs in df2: {unique_stayid_df2}\")\n","  print(f\"Difference in unique stay IDs: {difference}\\n\")\n","  # return unique_stayid_df1, unique_stayid_df2, difference\n"],"metadata":{"id":"NWinz5eOvsEW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# let's create df_demographics\n","\n","# start with age and keep ['subject_id', 'hadm_id', 'age'] and merge with patients, keeping ['subject_id', 'gender'] from the former and merged on subject_id\n","df_demographics = pd.merge(df_age[['subject_id', 'hadm_id', 'age']], df_patients[['subject_id', 'gender']], on='subject_id', how='left')\n","\n","# take  'race' 'language''insurance', in tht order, from df_admissions and put into df_demographics\n","df_demographics = pd.merge(df_demographics, df_admissions[['subject_id', 'hadm_id', 'race', 'language', 'insurance']], on=['subject_id', 'hadm_id'], how='left')\n"],"metadata":{"id":"Lza8lB2nwiGs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# first, subset icu_stays for stays where sepsis occurred\n","df_icustays_sepsis = df_icustays[df_icustays['stay_id'].isin(df_sepsis3['stay_id'])]\n","print(\"df_icustays_sepsis\")\n","compare_unique_stayid(df_icustays, df_icustays_sepsis)\n","\n","# first subset icustays on ['subject_id', 'hadm_id', 'stay_id', 'intime'] and merge with admissions, only keeping 'deathtime' and 'hospital_expire_flag' from admissions and merging on hadm_id\n","df_icustays_sepsis = pd.merge(df_icustays_sepsis[['subject_id', 'hadm_id', 'stay_id', 'intime']], df_admissions[['subject_id', 'hadm_id', 'deathtime', 'hospital_expire_flag']], on=['subject_id','hadm_id'], how='left')\n","\n","# now merge in from df_first_day_sofa by merging on stay_id, only retaining ['subject_id', 'hadm_id', 'stay_id', 'sofa'] from df_first_day_sofa (innter join)\n","df_icustays_sepsis_sofa = pd.merge(df_icustays_sepsis, df_first_day_sofa[['subject_id', 'hadm_id', 'stay_id', 'sofa']], on=['subject_id', 'hadm_id', 'stay_id'], how='inner')\n","\n","# now merge in 'charlson_comorbidity_index', merging on 'hadm_id'\n","df_icustays_sepsis_sofa_charl = pd.merge(df_icustays_sepsis_sofa, df_charlson[['subject_id', 'hadm_id', 'charlson_comorbidity_index']], on=['subject_id', 'hadm_id'], how='left')\n","\n","# now merge in df_demographics and call it df_cohort_v0\n","df_cohort_v0 = pd.merge(df_icustays_sepsis_sofa_charl, df_demographics, on=['subject_id', 'hadm_id'], how='left')\n","df_cohort_v0['over_24hr'] = (df_cohort_v0['deathtime'] - df_cohort_v0['intime']) > pd.Timedelta(hours=24)\n","\n","print(f\"Number of unique subject_id: {df_cohort_v0['subject_id'].nunique()}\")\n","print(f\"Number of unique stay_id: {df_cohort_v0['stay_id'].nunique()}\")\n","print(f\"Number of unique hadm_id: {df_cohort_v0['hadm_id'].nunique()}\")\n","display(df_cohort_v0['over_24hr'].value_counts())\n","display(df_cohort_v0)\n","\n","#save\n","df_cohort_v0.to_csv('/content/drive/MyDrive/DukeDatathon_2025_Team3/Brian/files/df_cohort_v0.csv', index=False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":216},"id":"-S7eATjGuJCb","executionInfo":{"status":"error","timestamp":1745752276969,"user_tz":240,"elapsed":9,"user":{"displayName":"Bryce Hendren-Santiago","userId":"18389451551274920537"}},"outputId":"dd869ff1-a4ac-4abe-da76-47d2f50bafc1"},"execution_count":2,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'df_icustays' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-4f09a4ddfa4b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# first, subset icu_stays for stays where sepsis occurred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_icustays_sepsis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_icustays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_icustays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stay_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_sepsis3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stay_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"df_icustays_sepsis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcompare_unique_stayid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_icustays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_icustays_sepsis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'df_icustays' is not defined"]}]},{"cell_type":"code","source":["# now subeset based on over_24hr\n","\n","df_cohort_v0_over24hr = df_cohort_v0[df_cohort_v0['over_24hr'] == True]\n","print(f\"Number of unique subject_id: {df_cohort_v0_over24hr['subject_id'].nunique()}\")\n","print(f\"Number of unique stay_id: {df_cohort_v0_over24hr['stay_id'].nunique()}\")\n","print(f\"Number of unique hadm_id: {df_cohort_v0_over24hr['hadm_id'].nunique()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"69uTVqzp4tVR","executionInfo":{"status":"ok","timestamp":1745717800343,"user_tz":240,"elapsed":8,"user":{"displayName":"Brian Lerner","userId":"16362064343865306362"}},"outputId":"fc0fcf27-cc62-4efc-ec65-9356451baca1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of unique subject_id: 4373\n","Number of unique stay_id: 4841\n","Number of unique hadm_id: 4373\n"]}]},{"cell_type":"code","source":["print(df_icustays_sepsis.head(10))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":144},"id":"fpPPXsfZ8Gq4","executionInfo":{"status":"error","timestamp":1745752245362,"user_tz":240,"elapsed":64,"user":{"displayName":"Bryce Hendren-Santiago","userId":"18389451551274920537"}},"outputId":"ecb8a548-4cb6-45d6-f87c-4d3b3d25b0e5"},"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'df_icustays_sepsis' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-a6ceaacf7df6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_icustays_sepsis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'df_icustays_sepsis' is not defined"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Z2AEjtKu8Sst"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1p6q5-zdW9GXLhweWRA4dNQlvsYoU1PUP","timestamp":1745693732758}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}